{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证数据集  \n",
    "\n",
    "之前我们会对数据集做train_test_split操作，将数据集分为两份    \n",
    "\n",
    "然后进行训练，使用测试数据的误差来评判模型的好坏，如果一次训练过后，模型的在测试集上的误差较大，就会调整超参数    \n",
    "直到调整到模型在测试数据集上有较好的性能，**但其实这样会使得模型在测试集上发生过拟合**   \n",
    "\n",
    "所以引入验证数据集，我们在数据集切分时，将数据集分为三份   \n",
    "\n",
    "然后使用训练集训练模型，使用验证集调整超参数，将测试集作为一个模型从未见过的一个模拟真实环境(生产环境)的数据集   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证数据集的意义\n",
    "\n",
    "* 验证数据集意义   \n",
    "    调整超参数使用的数据集   \n",
    "   \n",
    "* 测试数据集意义  \n",
    "    作为衡量最终模型性能的数据集   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先使用train_test_split的方法来调超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "# 使用kNN算法来进行测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score 0.9860917941585535\n",
      "best_k 3\n",
      "best_p 4\n"
     ]
    }
   ],
   "source": [
    "# 寻找KNN算法中的两个超参数的较优值，K，计算当前样本点与周围k个点的距离，p为距离超参数\n",
    "best_score, best_k, best_p = 0, 0, 0\n",
    "\n",
    "for k in range(2, 11):\n",
    "    for p in range(1, 6):\n",
    "        knn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=k, p=p)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_p = p\n",
    "            \n",
    "print(\"best_score\", best_score)\n",
    "print(\"best_k\", best_k)\n",
    "print(\"best_p\", best_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![crossvalidation](./img/crossvalidation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 首先将数据集分为训练集和测试集   \n",
    "* 对训练集均分成k份，上图中共分为了3份    \n",
    "* 对k份数据集进行组合，比如两份做训练集，剩下一份做验证数据集   \n",
    "* 这样就可以形成k种训练集和验证集的组合，每种组合都能训练出一个模型   \n",
    "* 我们对这k种模型得到的结果取均值来作为当前超参数发挥效果的得分（这里面使用k个模型的均值其实已经对异常值进行了处理）    \n",
    "* 如果当前这k种模型的得分并不好，就调节超参数继续进行上述过程 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98895028, 0.97777778, 0.96629213])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 创建一个默认参数的Knn分类器\n",
    "knn_clf = KNeighborsClassifier()\n",
    "# 直接将要进行交叉验证的分类器传入，然后传入当前的训练集\n",
    "cross_val_score(knn_clf, X_train, y_train)\n",
    "# 输出是三个得分，说明在当前默认超参数的情况下，对训练数据集进行了3次切分，分成了3份，然后对3个模型分别进行了计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score 0.9823599874006478\n",
      "best_k 2\n",
      "best_p 2\n"
     ]
    }
   ],
   "source": [
    "# 接下来对knn模型使用交叉验证的方式寻找最优超参数k和p\n",
    "best_score, best_p, best_k = 0, 0, 0\n",
    "for k in range(2, 11):\n",
    "    for p in range(1, 6):\n",
    "        knn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=k, p=p)\n",
    "        # 将当前超参数k和p创建的knn分类器传入交叉验证函数中\n",
    "        # 并将三个模型的得分进行记录\n",
    "        scores = cross_val_score(knn_clf, X_train, y_train)\n",
    "        # 计算三个模型得分的均值\n",
    "        score = np.mean(scores)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_p = p\n",
    "            best_k = k\n",
    "            \n",
    "print(\"best_score\", best_score)\n",
    "print(\"best_k\", best_k)\n",
    "print(\"best_p\", best_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.980528511821975"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过上面的交叉验证得到的最优的k和p，下面使用这两个最优超参数训练新的模型  \n",
    "knn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=2, p=2)\n",
    "# 使用训练数据集进行训练\n",
    "knn_clf.fit(X_train, y_train)\n",
    "# 使用测试集进行模型评价，这个测试集模型是没有见过的\n",
    "knn_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
