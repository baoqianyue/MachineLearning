{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BarackBao\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Data provider\n",
    "    a. Image data\n",
    "    b. random vector\n",
    "2. Build compute graph\n",
    "    a. generator\n",
    "    b. discriminator\n",
    "    c. DCGAN\n",
    "        connect g and d\n",
    "        define loss\n",
    "        define train_op\n",
    "3. train process\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os  \n",
    "import sys\n",
    "from tensorflow import logging\n",
    "from tensorflow import gfile\n",
    "import pprint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b1b81dbd1eba>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\BarackBao\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\BarackBao\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\BarackBao\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\BarackBao\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\BarackBao\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "32\n",
      "[128, 64, 32, 1]\n",
      "(55000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集 Mnist\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "output_dir = '.local_run'    \n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir)\n",
    "    \n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        z_dim = 100, # 输入向量size\n",
    "        init_conv_size = 4, # 反卷积层size\n",
    "        g_channels = [128, 64, 32, 1], # 生成器每一层反卷积的通道数\n",
    "        d_channels = [32, 64, 128, 256], # 判别器中每一层卷积层的通道数\n",
    "        batch_size = 128,\n",
    "        learning_rate = 0.002,\n",
    "        beta1 = 0.5, # adam参数\n",
    "        img_size = 32, # 反卷积size为4x4，所以要经过3次反卷积\n",
    "    )\n",
    "\n",
    "hps = get_default_params()\n",
    "print(hps.img_size)\n",
    "print(hps.g_channels)\n",
    "print(mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistData(object):\n",
    "    def __init__(self, mnist_train, z_dim, img_size):\n",
    "        self._data = mnist_train\n",
    "        self._example_num = len(mnist_train)\n",
    "        self._z_data = np.random.standard_normal((self._example_num, z_dim))\n",
    "        self._indicator = 0\n",
    "        self._random_shuffle()\n",
    "        self._resize_mnist_img(img_size)\n",
    "        \n",
    "    def _random_shuffle(self):\n",
    "        p = np.random.permutation(self._example_num)\n",
    "        self._z_data = self._z_data[p]\n",
    "        self._data = self._data[p]\n",
    "        \n",
    "    def _resize_mnist_img(self, img_size):\n",
    "        \"\"\"\n",
    "        resize mnist image to goal img_size\n",
    "        1. numpy -> PIL image\n",
    "        2. PIL image -> resize 28x28 -> 32x32\n",
    "        3. PIL image -> numpy\n",
    "        \"\"\"\n",
    "        data = np.asarray(self._data * 255, np.uint8) # 将原像素数据从0~1变为0~255\n",
    "        # [example_num, 784] -> [example_num, 28, 28]\n",
    "        data = data.reshape((self._example_num, 28, 28)) \n",
    "        new_data = []\n",
    "        for i in range(self._example_num):\n",
    "            img = data[i]\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.resize((img_size, img_size))\n",
    "            img = np.asarray(img)\n",
    "            img = img.reshape((img_size, img_size, 1))\n",
    "            new_data.append(img)\n",
    "            \n",
    "        new_data = np.asarray(new_data, dtype=np.float32)\n",
    "        new_data = new_data / 127.5 - 1 # -1 ~ 1 归一化，对应generator的tanH\n",
    "        # [num_example, img_size, img_size, 1]\n",
    "        self._data = new_data\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._example_num:\n",
    "            self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator < self._example_num\n",
    "        \n",
    "        batch_data = self._data[self._indicator : end_indicator]\n",
    "        batch_z = self._z_data[self._indicator : end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_z\n",
    "    \n",
    "mnist_data = MnistData(mnist.train.images, hps.z_dim, hps.img_size)\n",
    "batch_data, batch_z = mnist_data.next_batch(5)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_transpose(inputs, out_channel, name, training, with_bn_relu=True):\n",
    "    \"\"\"Wrapper of conv2d transpose\"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        conv2d_trans = tf.layers.conv2d_transpose(inputs, \n",
    "                                                  out_channel, \n",
    "                                                  [5, 5], \n",
    "                                                  strides=(2, 2), \n",
    "                                                  padding='same')\n",
    "        if with_bn_relu:\n",
    "            bn = tf.layers.batch_normalization(conv2d_trans,\n",
    "                                              training=training)\n",
    "            relu = tf.nn.relu(bn)\n",
    "            return relu\n",
    "        else:\n",
    "            return conv2d_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, channels, init_conv_size):\n",
    "        self._channels = channels\n",
    "        self._init_conv_size = init_conv_size\n",
    "        self._reuse = False # 重用开关\n",
    "        \n",
    "    \"\"\"将该对象想一个函数一样使用\"\"\"\n",
    "    def __call__(self, inputs, training):\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        with tf.variable_scope('generator', reuse=self._reuse):\n",
    "            \"\"\"\n",
    "            random_vector -> fc -> self._channels[0] * init_conv_size ** 2\n",
    "            -> reshape -> [init_conv_size, init_conv_size, channels[0]]\n",
    "            \"\"\"\n",
    "            with tf.variable_scope('inputs_conv'):\n",
    "                fc = tf.layers.dense(\n",
    "                    inputs,\n",
    "                    self._channels[0] * self._init_conv_size * _init_conv_size)\n",
    "                conv0 = tf.reshape(fc, [-1, self._init_conv_size, self._init_conv_size, self._channels[0]])\n",
    "                \n",
    "                bn0 = tf.layers.batch_normalization(conv0, training=training)\n",
    "                \n",
    "                relu0 = tf.nn.relu(bn0)\n",
    "            deconv_inputs = relu0\n",
    "            for i in range(1, len(self._channels)):\n",
    "                with_bn_relu = (i != len(self._channels) - 1) # 判断是否为最后一层\n",
    "                deconv_input = conv2d_transpose(\n",
    "                    deconv_inputs,\n",
    "                    self._channels[i],\n",
    "                    'deconv-%d'.format(i),\n",
    "                    training, \n",
    "                    with_bn_relu)\n",
    "            \n",
    "            img_inputs = deconv_inputs\n",
    "            with tf.variable_scope(\"generator_imgs\"):\n",
    "                # value [-1, 1]\n",
    "                imgs = tf.tanh(img_inputs, name='imgs') \n",
    "        self._reuse = True\n",
    "        self.variable = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "        return imgs      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inputs, out_channel, name, training):\n",
    "    def leaky_relu(x, leak=0.2, name=''):\n",
    "        return tf.maximum(x, leak * x, name=name)\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        conv2d_output = tf.layers.conv2d(inputs,\n",
    "                                        out_channel,\n",
    "                                        [5, 5],\n",
    "                                        strides=(2, 2),\n",
    "                                        padding='same')\n",
    "        bn = tf.layers.batch_normalization(conv2d_output,\n",
    "                                          training=training)\n",
    "        return leaky_relu(bn, name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self, channels):\n",
    "        self._channels = channels\n",
    "        self._reuse = False\n",
    "        \n",
    "    def __call__(self, inputs, training):\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        conv_inputs = inputs\n",
    "        with tf.variable_scope('discriminator', reuse=self.reuse):\n",
    "            for i in range(len(self._channels)):\n",
    "                conv_inputs = conv2d(conv_inputs, \n",
    "                                    self._channels[i],\n",
    "                                    'conv-%d'.format(i),\n",
    "                                    training)\n",
    "                fc_inputs = conv_inputs\n",
    "                with tf.variable_scope('fc'):\n",
    "                    # 先将输出结果拉平\n",
    "                    flatten = tf.contrib.flatten(fc_inputs)\n",
    "                    # 输出结果为0或1\n",
    "                    logits = tf.layers.dense(flatten, 2, name='logits')\n",
    "                self._reuse = True\n",
    "                self.variable = tf.get_collection(\n",
    "                    tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                    scope='discriminator'\n",
    "                )\n",
    "                return logits    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, hps):\n",
    "        g_channels = hps.g_channels\n",
    "        d_channels = hps.d_channels\n",
    "        self._batch_size = hps.batch_size\n",
    "        self._init_conv_size = hps.init_conv_size\n",
    "        self._z_dim = hps.z_dim\n",
    "        self._img_size = hps.img_size\n",
    "        self._generator = Generator(g_channels, self._init_conv_size)\n",
    "        self._discriminator = Discriminator(d_channels)\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\"Builds the compute graph\"\"\"\n",
    "        self._z_placeholder = tf.placeholder(\n",
    "            tf.float32, (self._batch_size, self._z_dim))\n",
    "        self._img_placeholder = tf.placeholder(\n",
    "            tf.float32, (self._batch_size, self._img_size, self._img_size, 1))\n",
    "        generated_imgs = self._generator(\n",
    "            self._z_placeholder, training=True)\n",
    "        fake_img_logits = self._discriminator(\n",
    "            generated_imgs, training=True)\n",
    "        real_img_logits = self._discriminator(\n",
    "            self._img_placeholder, training=True)\n",
    "        loss_on_fake_to_real = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = tf.ones([self._batch_size], dtype=tf.int64),\n",
    "                logits = fake_img_logits))\n",
    "        loss_on_fake_to_fake = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = tf.zeros([self._batch_size], dtype=tf.int64),\n",
    "                logits = fake_img_logits))\n",
    "        loss_on_real_to_real = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = tf.ones([self._batch_size], dtype=tf.int64),\n",
    "                logits = real_img_logits))\n",
    "        \n",
    "        tf.add_to_collection('g_losses', loss_on_fake_to_real)\n",
    "        tf.add_to_collection('d_losses', loss_on_fake_to_fake)\n",
    "        tf.add_to_collection('d_losses', loss_on_real_to_real)\n",
    "        \n",
    "        loss = {\n",
    "            'g' : tf.add_n(tf.get_collection('g_losses'),\n",
    "                          name='total_g_loss'),\n",
    "            'd' : tf.add_n(tf.get_collection('d_losses'),\n",
    "                          name='total_d_loss')\n",
    "        }\n",
    "        \n",
    "        return (self._z_placeholder,\n",
    "               self._img_placeholder,\n",
    "               generated_imgs,\n",
    "               loss)\n",
    "    \n",
    "    def build_train_op(self, losses, learning_rate, beta1):\n",
    "         \"\"\"build train op, should be called after build\"\"\"\n",
    "        g_opt = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate,\n",
    "            beta1=beta1)\n",
    "        d_opt = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate,\n",
    "            beta1=beta1)\n",
    "        g_opt_op = g_opt.minimize(\n",
    "            losses['g'], var_list=self._generator.variables)\n",
    "        d_opt_op = g_opt.minimize(\n",
    "            losses['d'], var_list=self._discriminator.variables)\n",
    "        \n",
    "        with tf.control_dependencies([g_opt_op, d_opt_op]):\n",
    "            return tf.no_op(name='train')\n",
    "\n",
    "dcgan = DCGAN(hps)\n",
    "z_placeholder, img_placeholder, generated_imgs, losses = dcgan.build()\n",
    "train_op = dcgan.build_train_op(losses, hps.learning_rate, hps.beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_imgs(batch_imgs, img_size, rows=8, cols=16):\n",
    "    # batch_imgs [batch_size, batch_size, img_size, 1]\n",
    "    result_big_img = []\n",
    "    for i in range(rows):\n",
    "        row_imgs = []\n",
    "        for j in range(cols):\n",
    "            # [batch_size, batch_size, 1]\n",
    "            img = batch_imgs[cols * i + j]\n",
    "            img = img.reshape((img_size, img_size))\n",
    "            img = (img + 1) * 127.5\n",
    "            row_imgs.append(img)\n",
    "        row_imgs = np.hstack(row_imgs)\n",
    "        result_big_img.append(row_imgs)\n",
    "    # [8x32, 16x32]\n",
    "    result_big_img = np.vstack(result_big_img)\n",
    "    result_big_img = np.asarray(result_big_img, np.uint8)\n",
    "    result_big_img = Image.fromarray(result_big_img)\n",
    "    return result_big_img\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "train_steps = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for step in range(train_steps):\n",
    "        batch_img, batch_z = mnist_data.next_batch(hps.batch_size)\n",
    "        fetches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
