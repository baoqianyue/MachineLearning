# 生成对抗网络 Generative Adversarial Network        

>  Goodfellow在2014年提出,他曾是Yoshua Bengio的学生      

> Yan LeCun 称赞GAN是"过去十年机器学习领域最有意思的想法"    

GAN的两大特点：  

* 不依赖任何先验假设，传统的很多方法都会假设数据服从某一分布，然后使用极大似然估计去估计数据分布     

* 生成`real-like`样本的方式很简单，通过生成器Generator的前向传播，而传统方法的采样方式非常复杂。    

这个网络需要同时训练两个模型，一个能够捕获数据分布的生成模型G，一个能够估计数据来源于真实样本概率的判别模型D     

生成器G的训练过程是最大化判别器犯错误的概率，即判别器误以为数据是真是样本而不是生成器生成的假样本，因此这个网络就对应于两个参与者的极小极大博弈(minmax game), 在所有可能的函数G和D中，我们可以求出唯一均衡解，即G可以生成与训练样本相同的分布，而D判断的概率处处为1/2      

GAN的缺点：  

* 模式崩塌(mode collapse)   
    假设我们希望学习的一个数据分布含有多种mode，但是GAN的机制就是G生成的图像能够骗过D的判别，在训练过程中，如果G只学习到了一种mode，同样能够通过D的判别，那这个网络就只能学习到一种mode，或者只能学习到一种mode的一部分。    

## 极小极大博弈      

为了学习到生成器在数据x上的分布P_g,我们先定义一个先验的输入噪声变量p_z(z),然后根据G(z;w_g)将其映射到数据空间中，其中G为生成器对应的可微函数，同时需要定义第二个网络D(s;w_d),它的输出为单个标量，**D(x)表示x来源于真是数据而不是P_g的概率**，我们训练D以最大正确分配真实样本和生成样本的概率，因此我们可以通过最小化log(1-D(G(z)))而同时训练G，也就是说判别器D和生成器G对价值函数V(G,D)进行极小极大博弈     

我们训练判别器D，让它在判别真实数据P_data时总是得到接近于1的结果，判别G生成的数据P_g时总是得到较差的结果，也就是接近于0      


其实极小极大博弈可以分开来看，即在给定G的情况下先最大化V(D,G)而获得D，然后固定D，并最小化V(D,G)而得到G，其中，给定G，最大化V(D,G)评估了P_g和P_data之间的差异或距离       
## CGAN(Condition GAN)   

原始GAN中，无法控制生成的内容，因为输出仅依赖于输入的随机噪声(G(z)), 如果在输入中加入一定的条件约束c，生成的图像就定义为G(z, c)，这就是条件GAN，通常输入条件矢量c和噪声矢量z可以直接连接，连接后就可以直接作为生成器的输入，网络的其他结构就和原始GAN相同，这里的输入条件可以是图像的类别，对象的属性或者其他的条件内容。     

![cgan](./image/cgan.png)   

上图中y就是条件矢量   


## DCGAN(Deep Convolutional Generative Adversarial Network)    
![dcgan](./image/dcgan.png)         

### 反卷积和卷积    

* 卷积   
    ![img](./image/convolution.png)    
    从图中的下层计算得到上层的操作   
    从矩阵运算的角度思考,将输入的4x4图像展开成16x1的矩阵X,然后将卷积核运算也展开,是4x16的一个矩阵C,卷积操作就是$Y = CX$,得到4x1的一个输出   

* 反卷积     
    ![img](./image/transconvolution.png)  
    对下层的2x2的单元进行padding,因为输出是4x4,所以做两个单位的padding,然后使用3x3的卷积核,步长为1   
    反卷积是卷积的逆过程,上面卷积的输入是4x4,输出是4x1    
    反卷积的输入就是4x1,输出是16x1     
    从矩阵运算的角度思考,反卷积操作就是$Y = C^TX$,这里X是输入4x1,$C^T$是卷积核运算展开C的转置,size为16x4,最后就可以得到反卷积输出为16x1    


### 模型结构     

* 1.Pooling层使用Convolution层代替(因为是从随机的少量数据来生成图片,使用池化层会丢失信息)     
    * D上使用strided convolution     
    * G上使用fractional-strided convolution(间隔关键点反卷积层)
        fractional-strided convolution也可以叫做deconvolution       

* 2.G和D都是用batch normailzation   
    * 可以帮助解决初始化数据较差的问题  
    * 可以使梯度传播到每一层,防止出现梯度弥散现象   
    * BN不应用于输入层和输出层(调参经验)       
    * 在D中移除了全连接层,采用了像ResNet中的global pooling    
    * G上除了输出层使用tanH以外其他都是用Relu     
    * D上使用leakyRelu,leakyRelu的斜率为0.2       

## 训练细节   

* 除了将图像像素值规划到[-1, 1]之间为了tanh激活函数做准备之外没有其他的预处理      
* 所有模型都使用mini-batch stochastic gradient desent(SGD)训练,mini-batch的大小是128    
* 所有的参数被初始化都使用0为均值,0.02为标准方差的标准正态分布       
* LeakyReLU的斜率为0.2     
* 之前的GAN使用动量加快收敛速度,这里使用Adam optimizer,learning_rate使用0.0002,动量参数β1使用0.5        

## 测试    

* LSUN   
    paper中提到在Large-scale Scene Understanding数据集上选取了至少三百万张图片进行训练   

* 论文中一直在强调DCGAN是真正学习到了语义特征而不是只是记住了图片,通过调整初始输入向量来探索隐空间是如何影响最终图像的生成,还可以观察到图像特征是如何折叠到隐空间中的      




 
### 生成器    

* 生成器网络有4个卷积层，除输出层外，其他所有层都紧接着批归一化(BN)和线性修正单元(ReLU)进行激活      

* 生成器将随机向量z(从正态分布中抽取)作为输入，向量z进行四维重塑后，送入生成器，启动一系列上采样层       

* 每个上采样层都代表了一个步长为2的转置卷积运算符，转置卷积运算与常规卷积运算类似         

* 常规卷积运算的层从宽而浅到窄而深，而转置卷积恰好相反：其层从窄而深到宽而浅       

* 转置卷积运算操作的步长定义了输出层的大小，在使用`same`填充时，步长为2时，输出特征图的尺寸将是输出层的大小的两倍         

* 将3x3的卷积核在2x2的输入上进行步长为2的转制卷积操作，相当于将3x3的卷积核在5x5的输入上进行步长为2的常规卷积操作        

    ![deconv](./image/fanconv.png)        

* 窄而深的输入向量是生成器的开始，在每次转置卷积之后，z变得更加宽而浅，所有转制卷积都使用5x5的卷积核，输入z深度由512降到3，这里的3代表RGB彩色图像的三个通道         

    ```python
    def transpose_conv2d(x, output_space):
        return tf.layers.conv2d_transpose(x, output_space,
            kernel_size=5, strides=2, padding='same', 
            kernel_initializer=tf.random_normal_initializer(mean=0.0, stddev=0.02)
        )
    ```    

* 最后一层输出一个32x32x3的tensor，并使用tanH函数将值压缩到-1到1之间      

    最终的输出尺寸有训练集图像的大小确定，如果使用Mnist数据集进行训练，则会生成28x28的灰度图像     


## Pix2Pix    

是GAN做图像翻译，转换的开山之作，但是该网络需要数据集是成对的图像，而且它只能学习到一对一的风格映射   



## CycleGAN   

该网络使用无监督训练(Unsupervised training)方式。  

数学形式表达：   
X和Y是两种不同类型的图像分布集，我们需要寻找一个映射$G:X -> Y$使得$y^{hat}=G(x)$   

该网络使用的数据集不是成对（paird data）数据集，所以无监督训练学习到的$y^{hat}$分布中含有无数种可能的映射，因为不能保证这种混合型的数据集中任意一个x对任意一个y的映射都有意义，所以训练过程中也会出现模式崩塌(mode collapse)的问题，为了解决该问题，CycleGAN中加入了图像转换中的一个特性来作为判别标准，**循环一致性(cycle consistent)**，比如将一个英文句子使用生成器G翻译成汉语，然后将汉语句子使用生成器F翻译回英语，理想状况下这两个英文句子应该是一样的，我们最优化的目标就是让这两个句子的差距最小。    

数学表示：  

英语到汉语翻译器G,x为英语句子    

$$
x -> G(x) -> F(G(x)) = x  
$$  

汉语到英语翻译器F，y为汉语句子   

$$
y -> F(y) -> G(F(y)) = y  
$$

