{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练流程\n",
    "* 1.Data provider \n",
    "    * a.Image data\n",
    "    * b.random vector  \n",
    "* 2.Build Compute graph  \n",
    "    * a.generator \n",
    "    * b.discriminator \n",
    "    * c.DCGAN class \n",
    "* 3.training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import logging\n",
    "from tensorflow import gfile\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../MNIST_data/', one_hot=True)# 加载数据\n",
    "output_dir = './local_run' # 输出文件夹路径\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir) # 创建输出文件夹\n",
    "\n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        z_dim = 100, # 随机噪声数据维度\n",
    "        init_conv_size = 4, # 将输入噪声变化成feature_map时,其初始size为4x4\n",
    "        g_channels = [128, 64, 32, 1],# 生成器中各反卷积层的通道数目\n",
    "        d_channels = [32, 64, 128, 256], # 判别器中各卷积层的通道数据,各个卷积层size减半,然后通道数加半,然后pooling\n",
    "        batch_size = 128, # 每批数量\n",
    "        learning_rate = 0.002, \n",
    "        beta1 = 0.5, # adam参数\n",
    "        img_size = 32, # 生成图像为32x32\n",
    "    )\n",
    "hparams = get_default_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data provider\n",
    "class MnistData(object):\n",
    "    # z_dim随机向量的长度, img_size,将train中的img resize成img_size\n",
    "    def __init__(self, mnist_train, z_dim, img_size):\n",
    "        self._data = mnist_train\n",
    "        self._example_num = len(self._data)\n",
    "        # 随机向量使用正态分布生成\n",
    "        self._z_data = np.random.standard_normal((self._example_num, z_dim)) \n",
    "        # next batch 指示器\n",
    "        self._indicator = 0\n",
    "        # resize 图像大小,参数为要resize到的图像大小\n",
    "        self._resize_mnist_img(img_size)\n",
    "        # shuffle函数\n",
    "        self._random_shuffle()\n",
    "        \n",
    "    def _random_shuffle(self):\n",
    "        x = np.random.permutation(self._example_num)\n",
    "        # 随机化train和z\n",
    "        self._data = self._data[x]\n",
    "        self._z_data = self._z_data[x]  \n",
    "    \n",
    "    def _resize_mnist_img(self, img_size):\n",
    "        \"\"\"resize the img to target imgsize,first numpy to PIL img\"\"\"\n",
    "        # 1.在mnist中图像都被归一化,所以先将图像灰度级恢复到0~255,像素值类型为整形\n",
    "        data = np.asarray(self._data * 255, np.uint8)\n",
    "        # 2. 像素数据 [example_num, 784] -> [example_num, 28, 28]\n",
    "        data = data.reshape((self._example_num, 28, 28))\n",
    "        # 3.将每幅图像插值成img_size * img_size\n",
    "        new_data = []\n",
    "        for i in range(self._example_num):\n",
    "            img = data[i]\n",
    "            # 将numpy数据变成PIL对象\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.resize((img_size, img_size))\n",
    "            # 再将PTL对象变成numpy对象\n",
    "            img = np.asarray(img)\n",
    "            # 判别器神经网络需要图像通道信息\n",
    "            img = img.reshape((img_size,img_size, 1))\n",
    "            new_data.append(img)\n",
    "        # 将resize后的全部图片转成numpy类型,new_data这里还是一个字典\n",
    "        new_data = np.asarray(new_data, dtype=np.float32)\n",
    "        # 将new_data归一化,这里将像素数据归一化到-1~1直接,为了配合generator,G中使用的是tanH\n",
    "        new_data = new_data / 127.5 - 1 \n",
    "        # self._data [example_num, img_size, img_size ,1]\n",
    "        self._data = new_data  \n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"下一batch\"\"\"\n",
    "        end_indicator = self._indicator + batch_size  \n",
    "        if end_indicator > self._example_num: \n",
    "            # 如果end超出数据范围,直接shuffle,重新划分\n",
    "            self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator < self._example_num\n",
    "        \n",
    "        batch_data = self._data[self._indicator : end_indicator]\n",
    "        batch_z = self._z_data[self._indicator : end_indicator]\n",
    "        # 将当前indicator置为end_indicator,以便下一批次数据划分\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_z \n",
    "\n",
    "mnist_data = MnistData(mnist.train.images, hparams.z_dim, hparams.img_size)\n",
    "batch_data, batch_z = mnist_data.next_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-8be7e373274d>, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-8be7e373274d>\"\u001b[1;36m, line \u001b[1;32m132\u001b[0m\n\u001b[1;33m    with tf.variable_scope('fc'):\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# generator \n",
    "def conv2d_transpose(inputs, out_channel, name, training, with_bn_relu=True):\n",
    "    \"\"\"\n",
    "    Wrapper of conv2d transpose\n",
    "    out_channel:每个反卷积层的通道数\n",
    "    name:该scope命名空间\n",
    "    training:在做卷积或者反卷积时都需要加一个bn操作,这里作为一个training开关\n",
    "    with_bn_relu=True:bn操作不作用于输出层和输入层,而且在生成器中其他层都使用relu激活,输出层使用tanH\n",
    "    所以这里默认为True,当到输出层时将该开关关闭\n",
    "    \"\"\"\n",
    "    conv2d_trans = tf.layers.conv2d_transpose(inputs,\n",
    "                                             out_channel,\n",
    "                                             [5,5],\n",
    "                                             strides=(2,2),\n",
    "                                             padding='SAME')\n",
    "    if with_bn_relu:\n",
    "        bn = tf.layers.batch_normalization(conv2d_trans, training=training)\n",
    "        return tf.nn.relu(bn)\n",
    "    else:\n",
    "        return conv2d_trans  \n",
    "    \n",
    "# discriminator \n",
    "def conv2d(inputs, out_channel, name, training):\n",
    "    \"\"\"\n",
    "    Wrapper of conv2d\n",
    "    out_channel:每个卷积层的通道数\n",
    "    name:该scope命名空间\n",
    "    training:卷积层后要做bn操作,这里给一个training开关\n",
    "    \"\"\"\n",
    "    # 判别器中使用leaky_relu,斜率为0.2\n",
    "    def leaky_relu(x, leak=0.2, name=' '):\n",
    "        return tf.maximum(x, x * leak, name=name)\n",
    "    \n",
    "    # 加入卷积层\n",
    "    with tf.variable_scope(name):\n",
    "        conv2d_output = tf.layers.conv2d(inputs,\n",
    "                                        out_channel,\n",
    "                                        [5,5],\n",
    "                                        strides=(2,2),# 这里步长为2,每次卷积输出是输入size的1/2\n",
    "                                        padding='SAME')\n",
    "        # 对卷积输出做bn操作\n",
    "        bn = tf.layers.batch_normalization(conv2d_output, training=training)\n",
    "        # 非线性变换\n",
    "        return leaky_relu(bn, name='outputs')\n",
    "        \n",
    "class Generator(object):\n",
    "    def __init__(self, channels, init_conv_size):\n",
    "        \"\"\"\n",
    "        channels:各个反卷积层中的通道数\n",
    "        \"\"\"\n",
    "        self._channels = channels\n",
    "        self._init_conv_size = init_conv_size\n",
    "        # reuse 开关,在第一次构建计算图完成后,就将该重用标志打开\n",
    "        self._reuse = False\n",
    "        \n",
    "    def __call__(self, inputs, training):\n",
    "        # 首先将输入数据转成tensor类型\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        with tf.variable_scope('generator', reuse=self._reuse):\n",
    "            \"\"\"\n",
    "            1.先对随机向量做一个fc层,参数W矩阵的size由init_conv_size给出\n",
    "            fc层仍是一个向量 \n",
    "            random_vector -> fc (size=[self.channels[0] * init_conv_size**2])\n",
    "            2.对fc层进行reshape,将其变换为一个三维矩阵形式(图像形式)\n",
    "            \"\"\"\n",
    "            with tf.variable_scope('inputs_conv'):\n",
    "                # fc层的size是self.channels[0] * init_conv_size ** 2\n",
    "                fc = tf.layers.dense(inputs, \n",
    "                                    self.channels[0] \n",
    "                                     * init_conv_size \n",
    "                                     * init_conv_size)\n",
    "                # 对fc层进行reshape成一个图像格式\n",
    "                # 可以看做是一个卷积层输出,shape参数中第一个-1是next_batch的大小\n",
    "                conv0 = tf.reshape(fc, [-1,\n",
    "                                       self._init_conv_size,\n",
    "                                       self._init_conv_size,\n",
    "                                       self._channels[0]])\n",
    "                # 对该图像bn操作\n",
    "                bn0 = tf.layers.batch_normalization(conv0, training=training)\n",
    "                # 非线性变换\n",
    "                relu0 = tf.nn.relu(bn0)\n",
    "                \n",
    "            # 进行反卷积操作\n",
    "            deconv_inputs = relu0 \n",
    "            # 循环实现多层反卷积,这里从1开始循环,因为真正反卷积的channel是从self._channels[1]开始的\n",
    "            for i in range(1, len(self._channels)):\n",
    "                # 首先要判断是否是生成器的输出层(是否是反卷积的最后一层),该层无需进行bn和relu操作\n",
    "                with_bn_relu = (i != len(self._channels) - 1)  \n",
    "                # 直接调用上面封装好的反卷积函数,将反卷积的输出保存在deconv_inputs中,方便下一步生成图像\n",
    "                deconv_inputs = conv2d_transpose(\n",
    "                    deconv_inputs,\n",
    "                    self._channels[i],\n",
    "                    'deconv-%d' % i,\n",
    "                    training,\n",
    "                    with_bn_relu)\n",
    "            # 对最后一个反卷积输出层使用tanH激活,生成图像,图像像素值范围为[-1,1]\n",
    "            img_inputs = deconv_inputs\n",
    "            with tf.variable_scope('generate_imgs'):\n",
    "                imgs = tf.tanh(img_inputs, name='imgs')\n",
    "        # 在第一次计算图构建完成后,将resue打开\n",
    "        self._reuse = True\n",
    "        \n",
    "        # 在GAN中,生成器和判别器是分开训练的,对应两个,所以两个网络中的参数也要分开保存 \n",
    "        self._variable = tf.get_collection(\n",
    "            tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "            scope='generator')\n",
    "        # 再将生成的图像返回\n",
    "        return imgs  \n",
    "    \n",
    "class Discriminator(object):\n",
    "    def __init__(self, channels):\n",
    "        self._channels = channels\n",
    "        self._reuse = False\n",
    "        \n",
    "    def __call__(self, inputs, training):\n",
    "        # 首先将输入数据转成tensor类型,然后再进行卷积操作\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        conv_inputs = inputs\n",
    "        with tf.variable_scope('discriminator'):\n",
    "            \"\"\"\n",
    "            1.直接对输入图像进行卷积操作\n",
    "            2.将卷积输出flatten\n",
    "            3.对flatten后的数据生成一个fc层,输出shape为2,值为0或1,表示当前判断结果\n",
    "            \"\"\"\n",
    "            for i in range(len(self._channels)):\n",
    "                conv_inputs = conv2d(conv_inputs,\n",
    "                                    self._channels[i],\n",
    "                                    'conv-%d' % i,\n",
    "                                    training)\n",
    "            # 全连接层\n",
    "            fc_inputs = conv_inputs\n",
    "            with tf.variable_scope('fc'):\n",
    "                flatten = tf.layers.flatten(fc_inputs)\n",
    "                logits = tf.layers.dense(fc_inputs, 2, name='logits')\n",
    "        # 网络构建后,将reuse开关打开\n",
    "        self._reuse = True\n",
    "        # 将判别器中的参数保存\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "        # 将判别器判别结果返回\n",
    "        return logits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
