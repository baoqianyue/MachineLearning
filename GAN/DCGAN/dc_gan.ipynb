{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练流程\n",
    "* 1.Data provider \n",
    "    * a.Image data\n",
    "    * b.random vector  \n",
    "* 2.Build Compute graph  \n",
    "    * a.generator \n",
    "    * b.discriminator \n",
    "    * c.DCGAN class \n",
    "* 3.training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import logging\n",
    "from tensorflow import gfile\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../MNIST_data/', one_hot=True)# 加载数据\n",
    "output_dir = './local_run' # 输出文件夹路径\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir) # 创建输出文件夹\n",
    "\n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        z_dim = 100, # 随机噪声数据维度\n",
    "        init_conv_size = 4, # 将输入噪声变化成feature_map时,其初始size为4x4\n",
    "        g_channels = [128, 64, 32, 1],# 生成器中各反卷积层的通道数目\n",
    "        d_channels = [32, 64, 128, 256], # 判别器中各卷积层的通道数据,各个卷积层size减半,然后通道数加半,然后pooling\n",
    "        batch_size = 128, # 每批数量\n",
    "        learning_rate = 0.002, \n",
    "        beta1 = 0.5, # adam参数\n",
    "        img_size = 32, # 生成图像为32x32\n",
    "    )\n",
    "hparams = get_default_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data provider\n",
    "class MnistData(object):\n",
    "    # z_dim随机向量的长度, img_size,将train中的img resize成img_size\n",
    "    def __init__(self, mnist_train, z_dim, img_size):\n",
    "        self._data = mnist_train\n",
    "        self._example_num = len(self._data)\n",
    "        # 随机向量使用正态分布生成\n",
    "        self._z_data = np.random.standard_normal((self._example_num, z_dim)) \n",
    "        # next batch 指示器\n",
    "        self._indicator = 0\n",
    "        # resize 图像大小,参数为要resize到的图像大小\n",
    "        self._resize_mnist_img(img_size)\n",
    "        # shuffle函数\n",
    "        self._random_shuffle()\n",
    "        \n",
    "    def _random_shuffle(self):\n",
    "        x = np.random.permutation(self._example_num)\n",
    "        # 随机化train和z\n",
    "        self._data = self._data[x]\n",
    "        self._z_data = self._z_data[x]  \n",
    "    \n",
    "    def _resize_mnist_img(self, img_size):\n",
    "        \"\"\"resize the img to target imgsize,first numpy to PIL img\"\"\"\n",
    "        # 1.在mnist中图像都被归一化,所以先将图像灰度级恢复到0~255,像素值类型为整形\n",
    "        data = np.asarray(self._data * 255, np.uint8)\n",
    "        # 2. 像素数据 [example_num, 784] -> [example_num, 28, 28]\n",
    "        data = data.reshape((self._example_num, 28, 28))\n",
    "        # 3.将每幅图像插值成img_size * img_size\n",
    "        new_data = []\n",
    "        for i in range(self._example_num):\n",
    "            img = data[i]\n",
    "            # 将numpy数据变成PIL对象\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.resize((img_size, img_size))\n",
    "            # 再将PTL对象变成numpy对象\n",
    "            img = np.asarray(img)\n",
    "            # 判别器神经网络需要图像通道信息\n",
    "            img = img.reshape((img_size,img_size, 1))\n",
    "            new_data.append(img)\n",
    "        # 将resize后的全部图片转成numpy类型,new_data这里还是一个字典\n",
    "        new_data = np.asarray(new_data, dtype=np.float32)\n",
    "        # 将new_data归一化,这里将像素数据归一化到-1~1直接,为了配合generator,G中使用的是tanH\n",
    "        new_data = new_data / 127.5 - 1 \n",
    "        # self._data [example_num, img_size, img_size ,1]\n",
    "        self._data = new_data  \n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"下一batch\"\"\"\n",
    "        end_indicator = self._indicator + batch_size  \n",
    "        if end_indicator > self._example_num: \n",
    "            # 如果end超出数据范围,直接shuffle,重新划分\n",
    "            self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator < self._example_num\n",
    "        \n",
    "        batch_data = self._data[self._indicator : end_indicator]\n",
    "        batch_z = self._z_data[self._indicator : end_indicator]\n",
    "        # 将当前indicator置为end_indicator,以便下一批次数据划分\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_z \n",
    "\n",
    "mnist_data = MnistData(mnist.train.images, hparams.z_dim, hparams.img_size)\n",
    "batch_data, batch_z = mnist_data.next_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator \n",
    "def conv2d_transpose(inputs, out_channel, name, training, with_bn_relu=True):\n",
    "    \"\"\"\n",
    "    Wrapper of conv2d transpose\n",
    "    out_channel:输出图像通道\n",
    "    name:该scope命名空间\n",
    "    training:在做卷积或者反卷积时都需要加一个bn操作,这里作为一个training开关\n",
    "    with_bn_relu=True:bn操作不作用于输出层和输入层,而且在生成器中其他层都使用relu激活,输出层使用tanH\n",
    "    所以这里默认为True,当到输出层时将该开关关闭\n",
    "    \"\"\"\n",
    "    conv2d_trans = tf.layers.conv2d_transpose(inputs,\n",
    "                                             out_channel,\n",
    "                                             [5,5],\n",
    "                                             strides=(2,2),\n",
    "                                             padding='SAME')\n",
    "    if with_bn_relu:\n",
    "        bn = tf.layers.batch_normalization(conv2d_trans, training=training)\n",
    "        return tf.nn.relu(bn)\n",
    "    else:\n",
    "        return conv2d_trans\n",
    "    \n",
    "class Generator(object):\n",
    "    def __init__(self, channels, init_conv_size):\n",
    "        \"\"\"\n",
    "        channels:各个反卷积层中的通道数\n",
    "        \"\"\"\n",
    "        self._channels = channels\n",
    "        self._init_conv_size = init_conv_size\n",
    "        # reuse 开关,在第一次构建计算图完成后,就将该重用标志打开\n",
    "        self._reuse = False\n",
    "        \n",
    "    def __call__(self, inputs, training):\n",
    "        # 首先将输入数据转成tensor类型\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        with tf.variable_scope('generator', resue=self._reuse):\n",
    "            \"\"\"\n",
    "            1.inputs -> fc \n",
    "            2.\n",
    "            \"\"\"\n",
    "        # 在第一次计算图构建完成后,将resue打开\n",
    "        self._reuse = True\n",
    "        \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
