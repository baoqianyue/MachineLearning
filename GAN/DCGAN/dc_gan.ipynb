{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练流程\n",
    "* 1.Data provider \n",
    "    * a.Image data\n",
    "    * b.random vector  \n",
    "* 2.Build Compute graph  \n",
    "    * a.generator \n",
    "    * b.discriminator \n",
    "    * c.DCGAN class \n",
    "* 3.training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import logging\n",
    "from tensorflow import gfile\n",
    "import sys\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../MNIST_data/', one_hot=True)# 加载数据\n",
    "output_dir = './local_run' # 输出文件夹路径\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir) # 创建输出文件夹\n",
    "\n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        z_dim = 100, # 随机噪声数据维度\n",
    "        init_conv_size = 4, # 将输入噪声变化成feature_map时,其初始size为4x4\n",
    "        g_channels = [128, 64, 32, 1],# 生成器中各反卷积层的通道数目\n",
    "        d_channels = [32, 64, 128, 256], # 判别器中各卷积层的通道数据,各个卷积层size减半,然后通道数加半,然后pooling\n",
    "        batch_size = 128, # 每批数量\n",
    "        learning_rate = 0.002, \n",
    "        beta1 = 0.5, # adam参数\n",
    "        img_size = 32, # 生成图像为32x32\n",
    "    )\n",
    "hparams = get_default_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data provider\n",
    "class MnistData(object):\n",
    "    # z_dim随机向量的长度, img_size,将train中的img resize成img_size\n",
    "    def __init__(self, mnist_train, z_dim, img_size):\n",
    "        self._data = mnist_train\n",
    "        self._example_num = len(self._data)\n",
    "        # 随机向量使用正态分布生成\n",
    "        self._z_data = np.random.standard_normal(self._example_num, z_dim) \n",
    "        # next batch 指示器\n",
    "        self._indicator = 0\n",
    "        # resize 图像大小,参数为要resize到的图像大小\n",
    "        self._resize_mnist_img(img_size)\n",
    "        # shuffle函数\n",
    "        self._random_shuffle()\n",
    "        \n",
    "    def _random_shuffle(self):\n",
    "        x = np.random.permutation(self._example_num)\n",
    "        # 随机化train和z\n",
    "        self._data = self._data[x]\n",
    "        self._z_data = self._z_data[x]  \n",
    "    \n",
    "    def _resize_mnist_img(self, img_size):\n",
    "        \"\"\"resize the img to target imgsize,first numpy to PIL img\"\"\"\n",
    "        # 1.在mnist中图像都被归一化,所以先将图像灰度级恢复到0~255,像素值类型为整形\n",
    "        data = np.asarray(self._data * 255, np.uint8)\n",
    "        # 2. 像素数据 [example_num, 784] -> [example_num, 28, 28]\n",
    "        data = np.reshape((self._example_num, 28, 28))\n",
    "        # 3.将每幅图像插值成img_size * img_size\n",
    "        new_data = []\n",
    "        for i in range(self._example_num):\n",
    "            img = data[i]\n",
    "            # 将numpy数据变成PIL对象\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.reshape((img_size, img_size))\n",
    "            # 再将PTL对象变成numpy对象\n",
    "            img = np.asarray(img)\n",
    "            # 判别器神经网络需要图像通道信息\n",
    "            img = np.reshape((img_size,img_size, 1))\n",
    "            new_data.append(img)\n",
    "        # 将resize后的全部图片转成numpy类型,new_data这里还是一个字典\n",
    "        new_data = np.asarray(new_data, dtype=np.float32)\n",
    "        # 将new_data归一化,这里将像素数据归一化到-1~1直接,为了配合generator,G中使用的是tanH\n",
    "        new_data = new_data / 127.5 - 1 \n",
    "        # self._data [example_num, img_size, img_size ,1]\n",
    "        self._data = new_data\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
