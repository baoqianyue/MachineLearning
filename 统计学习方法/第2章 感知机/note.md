# 感知机(Perceptron)     

感知机是面向二分类的线性分类模型，输入为样本实例的特征向量，输出只有两个值,-1和1，表示输入实例的类别。        

在几何意义上来看，感知机对应于在输入空间(特征空间)将实例划分为正负两类的一个超平面,为了找到最佳的划分平面，需要导入错误分类的损失函数，训练使该损失函数极小化，就可以求得感知机模型。    

感知机模型分为原始形式和对偶形式，1957年由Rosenblatt提出，感知机模型是神经网络和支持向量机的基础模型。     

## 感知机模型    

假设输入x为样本的特征向量，对应于特征空间中的一点，输出y表示该样本的类别，感知机就是从输入x到输出y的一个函数：   

$$f(x) = sign(\omega{x} + b)$$     

其中`ω`和`x`是感知机模型的参数，`ω`是权值(weight)或者权值向量(weight vector),`b`是偏置项(bias)     

`sign`是符号函数：   

$$
sign(x) = \left\{\begin{aligned}
+1 & & x \ge 0 \\  
-1 & & x < 0
\end{aligned}
\right. 
$$      

感知机模型的假设空间是由定义在特征空间中的所有线性分类模型构成的，所以线性划分方程：   

$$\omega{x} + b = 0$$     

对应于特征空间中的一个超平面，其中`w`是超平面的法向量，`b`是超平面的截距，将特征空间划分为两个区域。   

## 损失函数   

### 数据集的线性可分性    

上面提到感知机模型可以看作是特征空间中的一个划分平面，所以这里首先来介绍一下数据集的线性可分性     

给定一个数据集:   

$$T = {(x_1, y_1), (x_2, y_2),...,(x_N, y_N)}$$   

其中`xi`位于该数据集构成的特征空间中，`y={-1, +1},i = 1,2,...,N`，如果存在某个超平面S可以将该数据集中所有的正类点和负类点完全正确的划分到超平面的两侧，就称为该数据集T为线性可分数据集(linearly separable data set).   


### 学习策略   

为了找到合适的超平面，首先要导入一个能够描述错误分类的函数，而且这个函数需要是模型参数`w和b`的连续可导函数，方便优化。    

这里使用误分类点到超平面S的总距离