{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7E0048A3BDF948378AA3EB1D76DDC882","collapsed":false,"scrolled":false},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.examples.tutorials.mnist import input_data"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"4220FFF9705F43D1895A69A2981D1615","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting ./data/MNIST/train-images-idx3-ubyte.gz\nWARNING:tensorflow:From /opt/conda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting ./data/MNIST/train-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /opt/conda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\nExtracting ./data/MNIST/t10k-images-idx3-ubyte.gz\nExtracting ./data/MNIST/t10k-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /opt/conda/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","name":"stdout"}],"source":["mnist = input_data.read_data_sets(\"./data/MNIST/\", one_hot=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"179362B492514845899BC8145F700889","collapsed":false,"scrolled":false},"outputs":[],"source":["INPUT_NODE = 784\n","OUTPUT_NODE = 10\n","LAYER1_NODE = 500\n","BATCH_SIZE = 100"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"06CAB4CCBC4A45C388B265EEA6D2BCFD","collapsed":false,"scrolled":false},"outputs":[],"source":["# 模型相关参数\n","LEARNING_RATE_BASE = 0.8\n","LEARNING_RATE_DECAY = 0.99\n","REGULARAZTION_RATE = 0.0001\n","TRAINING_STEPS = 10000\n","MOVING_AVERAGE_DECAY = 0.99"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"EF034696972346D1B40DF1AD05CED797","collapsed":false,"scrolled":false},"outputs":[],"source":["def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n","    # 使用滑动平均类\n","    if avg_class == None:\n","        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n","        return tf.matmul(layer1, weights2) + biases2\n","    else:\n","        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n","        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)\n","\n","\n","def train(mnist):\n","    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n","    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n","\n","    # 生成隐层参数\n","    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n","    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n","\n","    # 生成输出层参数\n","    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n","    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n","\n","    # 计算不含滑动平均类的前向传播结果\n","    y = inference(x, None, weights1, biases1, weights2, biases2)\n","    \n","    # 训练轮数及滑动平均类\n","    global_step = tf.Variable(0, trainable=False)\n","    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n","    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n","    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n","\n","    # 定义交叉熵及其均值\n","    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n","    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n","\n","    # 定义交叉熵加上正则项\n","    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n","    regularaztion = regularizer(weights1) + regularizer(weights2)\n","    loss = cross_entropy_mean + regularaztion\n","    \n","    # 设置指数衰减的学习率\n","    learning_rate = tf.train.exponential_decay(\n","        LEARNING_RATE_BASE,\n","        global_step,\n","        mnist.train.num_examples / BATCH_SIZE,\n","        LEARNING_RATE_DECAY,\n","        staircase=True\n","    )\n","    \n","    # std优化\n","    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n","    \n","    # bp更新参数并更新每一个参数的滑动平均值\n","    with tf.control_dependencies([train_step, variables_averages_op]):\n","        train_op = tf.no_op(name='train')\n","        \n","    # 计算准确度\n","    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    \n","    # 初始化sess训练\n","    with tf.Session() as sess:\n","        tf.global_variables_initializer().run()\n","        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n","        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n","        \n","        # \n","        for i in range(TRAINING_STEPS):\n","            if i % 1000 == 0:\n","                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n","                print(\"After %d training step(s), validation accuracy is %g\" % (i, validate_acc))\n","                \n","            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n","            sess.run(train_op, feed_dict={x:xs, y_:ys})\n","            \n","        test_acc = sess.run(accuracy, feed_dict=test_feed)\n","        print((\"After %d training step(s), test accuracy is %g\" % (TRAINING_STEPS, test_acc)))"]},{"metadata":{"id":"0089D19EE6F44798858181CF7810E705","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"After 0 training step(s), validation accuracy is 0.1288\nAfter 1000 training step(s), validation accuracy is 0.9758\nAfter 2000 training step(s), validation accuracy is 0.9804\nAfter 3000 training step(s), validation accuracy is 0.9818\nAfter 4000 training step(s), validation accuracy is 0.9828\nAfter 5000 training step(s), validation accuracy is 0.9836\nAfter 6000 training step(s), validation accuracy is 0.9844\nAfter 7000 training step(s), validation accuracy is 0.9836\nAfter 8000 training step(s), validation accuracy is 0.9844\nAfter 9000 training step(s), validation accuracy is 0.984\nAfter 10000 training step(s), test accuracy is 0.9836\n","name":"stdout"}],"source":["arg_class = None\n","train(mnist)"],"execution_count":23}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}