# 数据预处理   

在数据挖掘的过程中，数据预处理的工作占到了60%左右。    

主要内容包括了数据清洗，数据集成，数据变换和数据规约。   

## 数据清洗  

主要工作是删除原始数据集中的无关数据、重复数据、平滑噪声数据、筛选掉与挖掘主题无关的数据，处理缺失值、异常值等。   

### 缺失值的处理   

* 数据删除   
* 不处理  
* 数据插值   
    * 牛顿插值法   
    * 拉格朗日插值法   
        Scipy库中实现了拉格朗日插值法   
        使用拉格朗日插值法填补餐厅营业额中的缺失值    
        ```python
        import pandas as pd
        from scipy.interpolate import lagrange

        inputfile = '../data/catering_sale.xls'
        outputfile = '../tmp/sales.xls'

        data = pd.read_excel(inputfile)
        print(data.describe())
        # DataFrame.info()返回每个数据列的列名，以及每列非non的个数
        print(data.info())  # 这里发现有一天的销量数据丢失

        # 过滤异常值
        data[u'销量'][(data[u'销量'] < 400) | (data[u'销量'] > 5000)] = None


        # 定义插值函数
        def ployinterp_col(col, n, k=5):
            """
            :param col: col指被插值的列向量
            :param n: n指插值的位置
            :param k: k插值时考虑周围数据的量度
            :return:
            """
            # 获取用作插值运算的数据
            y = col[list(range(n - k, n)) + list(range(n + 1, n + 1 + k))]
            y = y[y.notnull()]  # 剔除空值
            return lagrange(y.index, list(y))(n)  # 插值并返回插值结果


        # 逐个元素判断是否需要进行插值
        for i in data.columns:
            for j in range(len(data)):
                if (data[i].isnull())[j]:  # 如果为空就需要进行插值
                    data[i][j] = ployinterp_col(data[i], j)

        data.to_excel(outputfile)
        ```  

## 数据变换  

### 简单函数变换   

* 简单的函数变换常用来将不具有正态分布的数据变换为具有正态分布的数据。    
* 某些简单的对数变换或者差分运算可以将非平稳序列转换为平稳序列   

* 使用对数变换还可以将动态范围压缩   


### 规范化   

数据规范化对于基于距离的挖掘算法尤为重要   

* 最小最大值规范化   

    $$x^* = \frac{x - min}{max - min}$$   

    规划范围为[0,1]   

    缺点是如果原数据中有某个特别大的数据，会导致规范化后的结果接近于0   

* 均值规范化   

    $$x^* = \frac{x - \overline{x}}{\sigma}$$   
    
    其中$\overline{x}$是原始数据的均值，$\sigma$为原始数据的标准差   
    经过该处理的数据均值为0，标准差为1    
    
* 小数定标规范化  

    移动数据的小数点位置，将属性值映射到[-1, 1]之间，移动的小数位数取决于原始数据绝对值的最大值    

    $$x^* = \frac{x}{10^k}$$    

* 分别使用上述三种规范化方法对一组数据进行操作       

    ```python
    import pandas as pd
    import numpy as np

    datafile = '../data/normalization_data.xls'
    data = pd.read_excel(datafile, header=None)

    # 最小最大值规范化
    print((data - data.min()) / (data.max() - data.min()))

    # 均值规范化
    print((data - data.mean()) / data.std())

    # 小数定标规范化
    print(data / 10 ** np.ceil(np.log10(data.abs().max())))
    ```   


### 连续属性离散化     

连续属性的离散化是在数据的取值范围内设定若干个离散的划分点，形成多个离散化的区间，然后用各个区间的标志或者整数值来代表每个子区间中的数据    

* 等宽法     

    将属性的取值范围划分成具有相同宽度的区间，区间的个数由数据本身的特点决定，或者人为指定   

* 等频法   

    将出现次数相同的记录放到一个区间中     

    缺点是对于离群点比较敏感，会导致最后属性值的分布不均匀,有的区间的数据很多，有的区间数据很少   

* 基于聚类分析的方法   

    使用K-Means算法进行聚，然后将聚类得到的簇进行处理.     

    