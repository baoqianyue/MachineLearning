{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1607104130 鲍骞月 Naive-Bayes垃圾邮件分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伯努利模型实现    \n",
    "* 1. 准备数据   \n",
    "    * 1.1 加载数据   \n",
    "    * 1.2 对字符串进行划分（正则表达式），切分出单词    \n",
    "    * 1.3 根据切分出的单词构成词表（无重复）\n",
    "* 2. 特征选择      \n",
    "    * 以词表中的每一个单词在一个样本中是否出现作为特征     \n",
    "    * 词袋模型特征    \n",
    "* 3. 训练模型    \n",
    "    * 训练数据集划分（train_test_splite）    \n",
    "    * 计算每个样本的词向量    \n",
    "    * 根据词向量计算概率    \n",
    "    * 根据概率结果得出分类结果    \n",
    "* 4. 测试模型    \n",
    "    * 使用测试数据集计算分类错误率     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备数据   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re \n",
    "import math \n",
    "\n",
    "def textParse(res_string):\n",
    "    # 使用正则表达式切分单词\n",
    "    listOfTokens = re.split(r'\\W*',res_string)\n",
    "    # 过滤小于两个字符的单词，同时将单词全部小写   \n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据 \n",
    "docList = []\n",
    "classList = []\n",
    "fullText = []  \n",
    "\n",
    "# 读取文件  \n",
    "for i in list(range(1, 26)):\n",
    "    # 加载垃圾邮件数据   \n",
    "    wordList = textParse(open('./email/spam/%d.txt' % i, encoding=\"ISO-8859-1\").read())\n",
    "    docList.append(wordList)\n",
    "    fullText.extend(wordList)\n",
    "    classList.append(1)\n",
    "    # 加载正常邮件数据\n",
    "    wordList = textParse(open('./email/ham/%d.txt' % i, encoding=\"ISO-8859-1\").read())\n",
    "    docList.append(wordList)\n",
    "    fullText.extend(wordList)\n",
    "    classList.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造词表   \n",
    "def createVocabList(dataSet):\n",
    "    return list(set([y for x in dataSet for y in x]))  \n",
    "\n",
    "vocabList = createVocabList(docList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 特征计算      \n",
    "\n",
    "Bag of Word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWords2VecMN(vocabList,inputSet):\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else:\n",
    "            print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练模型       \n",
    "\n",
    "### Train—Test—Split    \n",
    "从50个邮件中，随机挑选出40个作为训练集,10个做测试集  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)  # 设定随机种子\n",
    "\n",
    "trainingSet = list(range(len(wordList)))    \n",
    "testSet = []\n",
    "for i in list(range(10)):\n",
    "    # 随机\n",
    "    randIndex = int(np.random.uniform(0,len(trainingSet)))\n",
    "    testSet.append(trainingSet[randIndex])\n",
    "    del(trainingSet[randIndex])   \n",
    "# 构建训练样本矩阵    \n",
    "trainMat = []\n",
    "trainClasses = []\n",
    "for docIndex in trainingSet:\n",
    "    trainMat.append(bagOfWords2VecMN(vocabList,docList[docIndex]))\n",
    "    trainClasses.append(classList[docIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过词向量计算概率    \n",
    "\n",
    "文档 d 属于类别 c 的概率计算如下（多项式模型）：\n",
    "$$P(c|d)=\\frac{P(d|c)P(c)}{P(d)} \\propto P(d|c)P(c) = P(c)\\prod_{1\\leq k \\leq n_{d}}P(t_{k} | c) $$\n",
    "$n_{d}$ 是文档的长度（词条个数）     \n",
    "$P(t_{k}|c)$  是词项  $t_{k}$ 出现在类别 c 中文档的频率      \n",
    "$P(t_{k}|c)$  度量的是当 c 是正确类别时  $t_{k}$  的贡献     \n",
    "p(c)是类别 c 的先验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    numTrainDocs = len(trainMatrix) # 句子，样本数\n",
    "    numWords = len(trainMatrix[0])  # 词向量长度\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs) # 类别为1的样本占比\n",
    "    p0Num = np.ones(numWords)\n",
    "    p1Num = np.ones(numWords)\n",
    "    p0Denom = 2.0\n",
    "    p1Denom = 2.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]        # 向量：样本汇总，所有样本加到一个词向量长度的向量\n",
    "            p1Denom += sum(trainMatrix[i]) # 标量：所有单词计数\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "    p1Vect = np.log(p1Num/p1Denom)   # 向量，训练数据中归为1类的样本统计出的，词向量中每个元素出现的概率\n",
    "    p0Vect = np.log(p0Num/p0Denom)  \n",
    "    return p0Vect, p1Vect, pAbusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 计算概率   \n",
    "p0V,p1V,pSpam = trainNB0(np.array(trainMat),np.array(trainClasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类函数    \n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    # 使用log防止出现0\n",
    "    p1 = sum(vec2Classify*p1Vec) + np.log(pClass1)\n",
    "    p0 = sum(vec2Classify*p0Vec) + np.log(1-pClass1)\n",
    "    return 1 if p1 > p0 else 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 测试模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate is :  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barackbao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "errorCount = 0\n",
    "for docIndex in testSet:\n",
    "    wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])\n",
    "    if classifyNB(np.array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
    "        errorCount += 1\n",
    "print(\"the error rate is : \", errorCount/len(testSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn中伯努利贝叶斯分类实现   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "import glob\n",
    "\n",
    "# ham\n",
    "files = \"./email/ham/*.txt\"\n",
    "ham_lst = glob.glob(files)\n",
    "labels = [0]*len(ham_lst)\n",
    "files = \"./email/spam/*.txt\"\n",
    "spam_lst = glob.glob(files)\n",
    "lst = ham_lst + spam_lst\n",
    "labels.extend([1]*len(spam_lst))\n",
    "cVct = text.CountVectorizer(input=\"filename\",encoding=\"latin_1\")\n",
    "X = cVct.fit_transform(lst).todense().A\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate is 0.00%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)\n",
    "bnb.fit(X_train,y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "print(\"error rate is %1.2f%%\" % (100*np.mean(y_pred != y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
